{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMhIReoD6a/fYR3n/VboNps",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Benqui/facial-recognition-on-keras/blob/main/Reconocimiento_facial_de_emociones.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "LRSJ5FeRwqku",
        "outputId": "4df48736-f25b-4659-c65e-5ae65b7a74c2"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-ffb6433b096e>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'matplotlib'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mbrewer2mpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'brewer2mpl'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ],
      "source": [
        "from keras.utils.np_utils import to_categorical\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import warnings \n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import brewer2mpl\n",
        "\n",
        "\n",
        "def emotion_count(y_train, classes):\n",
        "    \"\"\"\n",
        "    The function re-classify picture with disgust label into angry label\n",
        "    \"\"\"\n",
        "    emo_classcount = {}\n",
        "    print ('Disgust classified as Angry')\n",
        "    y_train.loc[y_train == 1] = 0\n",
        "    classes.remove('Disgust')\n",
        "    for new_num, _class in enumerate(classes):\n",
        "        y_train.loc[(y_train == emotion[_class])] = new_num\n",
        "        class_count = sum(y_train == (new_num))\n",
        "        emo_classcount[_class] = (new_num, class_count)\n",
        "    return y_train.values, emo_classcount\n",
        "\n",
        "def load_data(sample_split=0.3, usage='Training',classes=['Angry','Happy'], filepath='../input/fer20131.csv'):\n",
        "    \"\"\"\n",
        "    The function load provided CSV dataset and further reshape, rescale the data for feeding\n",
        "    \"\"\"\n",
        "    df = pd.read_csv(filepath)\n",
        "    df = df[df.Usage == usage]\n",
        "    frames = []\n",
        "    classes.append('Disgust')\n",
        "    for _class in classes:\n",
        "        class_df = df[df['emotion'] == emotion[_class]]\n",
        "        frames.append(class_df)\n",
        "    data = pd.concat(frames, axis=0)\n",
        "    rows = random.sample(list(data.index), int(len(data)*sample_split))\n",
        "    data = data.loc[rows]\n",
        "    x = list(data[\"pixels\"])\n",
        "    X = []\n",
        "    for i in range(len(x)):\n",
        "        each_pixel = [int(num) for num in x[i].split()]\n",
        "        X.append(each_pixel)\n",
        "    ## reshape into 48*48*1 and rescale\n",
        "    X = np.array(X)\n",
        "    X = X.reshape(X.shape[0], 48, 48,1)\n",
        "    X = X.astype(\"float32\")\n",
        "    X /= 255\n",
        "    \n",
        "    y_train, new_dict = emotion_count(data.emotion, classes)\n",
        "    y_train = to_categorical(y_train)\n",
        "    return X, y_train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## All three datasets are well loaded accordingly\n",
        "emotion = {'Angry': 0, 'Disgust': 1, 'Fear': 2, 'Happy': 3,\n",
        "           'Sad': 4, 'Surprise': 5, 'Neutral': 6}\n",
        "emo     = ['Angry', 'Fear', 'Happy',\n",
        "           'Sad', 'Surprise', 'Neutral']\n",
        "\n",
        "X_test, y_test = load_data(sample_split=1.0,classes=emo,\n",
        "usage='PrivateTest')\n",
        "\n",
        "X_train, y_train = load_data(sample_split=1.0,classes=emo,\n",
        "usage= 'Training')\n",
        "\n",
        "X_val,y_val = load_data(sample_split=1.0,classes=emo,\n",
        "usage= 'PublicTest')"
      ],
      "metadata": {
        "id": "Ojeu8VYkxaVT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n",
        "print(X_val.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "id": "DqsrBMfExdlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_data(X_test, y_test, fname=''):\n",
        "    \"\"\"\n",
        "    The function stores loaded data into numpy form for further processing\n",
        "    \"\"\"\n",
        "    np.save( 'X_test' + fname, X_test)\n",
        "    np.save( 'y_test' + fname, y_test)\n",
        "save_data(X_test, y_test,\"_privatetest6_100pct\")\n",
        "X_fname = 'X_test_privatetest6_100pct.npy'\n",
        "y_fname = 'y_test_privatetest6_100pct.npy'\n",
        "X = np.load(X_fname)\n",
        "y = np.load(y_fname)\n",
        "print ('Private test set')\n",
        "y_labels = [np.argmax(lst) for lst in y]\n",
        "counts = np.bincount(y_labels)\n",
        "labels = ['angry', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
        "print (zip(labels, counts))"
      ],
      "metadata": {
        "id": "S9nR2jmOxhDh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def overview(start, end, X):\n",
        "    \"\"\"\n",
        "    The function is used to plot first several pictures for overviewing inputs format\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(20,20))\n",
        "    for i in range(start, end+1):\n",
        "        input_img = X[i:(i+1),:,:,:]\n",
        "        ax = fig.add_subplot(16,12,i+1)\n",
        "        ax.imshow(input_img[0,:,:,0], cmap=plt.cm.gray)\n",
        "        plt.xticks(np.array([]))\n",
        "        plt.yticks(np.array([]))\n",
        "        plt.tight_layout()\n",
        "    plt.show()\n",
        "overview(0,191, X)"
      ],
      "metadata": {
        "id": "im-iYlHRxkov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Similarly we canvisualize any input with self-defined index with following code\n",
        "input_img = X[6:7,:,:,:] \n",
        "print (input_img.shape)\n",
        "plt.imshow(input_img[0,:,:,0], cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xXyFnvy_xnvW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = y_train \n",
        "y_public = y_val \n",
        "y_private = y_test \n",
        "y_train_labels  = [np.argmax(lst) for lst in y_train]\n",
        "y_public_labels = [np.argmax(lst) for lst in y_public]\n",
        "y_private_labels = [np.argmax(lst) for lst in y_private]"
      ],
      "metadata": {
        "id": "nPWuSETQxo4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_distribution(y1, y2, data_names, ylims =[1000,1000]): \n",
        "    \"\"\"\n",
        "    The function is used to plot the distribution of the labels of provided dataset \n",
        "    \"\"\"\n",
        "    colorset = brewer2mpl.get_map('Set3', 'qualitative', 6).mpl_colors\n",
        "    fig = plt.figure(figsize=(8,4))\n",
        "    ax1 = fig.add_subplot(1,2,1)\n",
        "    ax1.bar(np.arange(1,7), np.bincount(y1), color=colorset, alpha=0.8)\n",
        "    ax1.set_xticks(np.arange(1.25,7.25,1))\n",
        "    ax1.set_xticklabels(labels, rotation=60, fontsize=14)\n",
        "    ax1.set_xlim([0, 8])\n",
        "    ax1.set_ylim([0, ylims[0]])\n",
        "    ax1.set_title(data_names[0])\n",
        "    \n",
        "    ax2 = fig.add_subplot(1,2,2)\n",
        "    ax2.bar(np.arange(1,7), np.bincount(y2), color=colorset, alpha=0.8)\n",
        "    ax2.set_xticks(np.arange(1.25,7.24,1))\n",
        "    ax2.set_xticklabels(labels, rotation=60, fontsize=14)\n",
        "    ax2.set_xlim([0, 8])\n",
        "    ax2.set_ylim([0, ylims[1]])\n",
        "    ax2.set_title(data_names[1])\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "plot_distribution(y_train_labels, y_public_labels, \\\n",
        "                  ['Train dataset', 'Public dataset'], \\\n",
        "                  ylims =[8000,1000]) "
      ],
      "metadata": {
        "id": "lRb6tdy6xq1Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "\n",
        "modelN = models.Sequential()\n",
        "modelN.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu',\n",
        "                        input_shape=(48, 48, 1)))\n",
        "modelN.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "modelN.add(layers.Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
        "modelN.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "modelN.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "modelN.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "modelN.add(layers.Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
        "modelN.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "modelN.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "modelN.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "modelN.add(layers.Conv2D(128, (3, 3), padding='same', activation='relu'))\n",
        "modelN.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "modelN.add(layers.Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
        "modelN.add(layers.Dense(64, activation='relu'))\n",
        "modelN.add(layers.Dense(64, activation='relu'))\n",
        "modelN.add(layers.Dense(6, activation='softmax'))\n",
        "\n",
        "# optimizer:\n",
        "modelN.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print ('Training....')\n",
        "\n",
        "\n",
        "#fit\n",
        "nb_epoch = 32\n",
        "batch_size = 128\n",
        "\n",
        "modelF = modelN.fit(X_train, y_train, nb_epoch=nb_epoch, batch_size=batch_size,\n",
        "          validation_data=(X_val, y_val), shuffle=True, verbose=1)"
      ],
      "metadata": {
        "id": "a9FdU8hWxxve"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelN.save('facial_1')\n",
        "\n",
        "acc = modelF.history['acc']\n",
        "val_acc = modelF.history['val_acc']\n",
        "loss = modelF.history['loss']\n",
        "val_loss = modelF.history['val_loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "MBuZkJcPxz5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model on private test set\n",
        "score = modelN.evaluate(X, y, verbose=0)\n",
        "print (\"model %s: %.2f%%\" % (modelN.metrics_names[1], score[1]*100))\n"
      ],
      "metadata": {
        "id": "HTn-8_5ax5aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction and true labels\n",
        "y_prob = modelN.predict(X, batch_size=32, verbose=0)\n",
        "y_pred = [np.argmax(prob) for prob in y_prob]\n",
        "y_true = [np.argmax(true) for true in y]"
      ],
      "metadata": {
        "id": "rGajaAu2x6eS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_subjects(start, end, y_pred, y_true, title=False):\n",
        "    \"\"\"\n",
        "    The function is used to plot the picture subjects\n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    emotion = {0:'Angry', 1:'Fear', 2:'Happy', 3:'Sad', 4:'Surprise', 5:'Neutral'}\n",
        "    for i in range(start, end+1):\n",
        "        input_img = X[i:(i+1),:,:,:]\n",
        "        ax = fig.add_subplot(6,6,i+1)\n",
        "        ax.imshow(input_img[0,:,:,0], cmap=matplotlib.cm.gray)\n",
        "        plt.xticks(np.array([]))\n",
        "        plt.yticks(np.array([]))\n",
        "        if y_pred[i] != y_true[i]:\n",
        "            plt.xlabel(emotion[y_true[i]], color='#53b3cb',fontsize=12)\n",
        "        else:\n",
        "            plt.xlabel(emotion[y_true[i]], fontsize=12)\n",
        "        if title:\n",
        "            plt.title(emotion[y_pred[i]], color='blue')\n",
        "        plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "h4tJmKamx9Sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import brewer2mpl\n",
        "def plot_probs(start,end, y_prob):\n",
        "    \"\"\"\n",
        "    The function is used to plot the probability in histogram for six labels \n",
        "    \"\"\"\n",
        "    fig = plt.figure(figsize=(12,12))\n",
        "    for i in range(start, end+1):\n",
        "        input_img = X[i:(i+1),:,:,:]\n",
        "        ax = fig.add_subplot(6,6,i+1)\n",
        "        set3 = brewer2mpl.get_map('Set3', 'qualitative', 6).mpl_colors\n",
        "        ax.bar(np.arange(0,6), y_prob[i], color=set3,alpha=0.5)\n",
        "        ax.set_xticks(np.arange(0.5,6.5,1))\n",
        "        labels = ['angry', 'fear', 'happy', 'sad', 'surprise','neutral']\n",
        "        ax.set_xticklabels(labels, rotation=90, fontsize=10)\n",
        "        ax.set_yticks(np.arange(0.0,1.1,0.5))\n",
        "        plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "Y2ByjWRmx-ZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_subjects_with_probs(start, end, y_prob):\n",
        "    \"\"\"\n",
        "    This plotting function is used to plot the probability together with its picture\n",
        "    \"\"\"\n",
        "    iter = int((end - start)/6)\n",
        "    for i in np.arange(0,iter):\n",
        "        plot_subjects(i*6,(i+1)*6-1, y_pred, y_true, title=False)\n",
        "        plot_probs(i*6,(i+1)*6-1, y_prob)"
      ],
      "metadata": {
        "id": "NJw6C72jyAo6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_distribution2(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    The function is used to compare the number of true labels as well as prediction results\n",
        "    \"\"\"\n",
        "    colorset = brewer2mpl.get_map('Set3', 'qualitative', 6).mpl_colors\n",
        "    ind = np.arange(1.5,7,1)  # the x locations for the groups\n",
        "    width = 0.35   \n",
        "    fig, ax = plt.subplots()\n",
        "    true = ax.bar(ind, np.bincount(y_true), width, color=colorset, alpha=1.0)\n",
        "    pred = ax.bar(ind + width, np.bincount(y_pred), width, color=colorset, alpha=0.3)\n",
        "    ax.set_xticks(np.arange(1.5,7,1))\n",
        "    ax.set_xticklabels(labels, rotation=30, fontsize=14)\n",
        "    ax.set_xlim([1.25, 7.5])\n",
        "    ax.set_ylim([0, 1000])\n",
        "    ax.set_title('True and Predicted Label Count (Private)')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "plot_distribution2(y_true, y_pred)"
      ],
      "metadata": {
        "id": "TsY1HtpgyEhL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "def plot_confusion_matrix(y_true, y_pred, cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    The function is used to construct the confusion matrix \n",
        "    \"\"\"\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    fig = plt.figure(figsize=(6,6))\n",
        "    matplotlib.rcParams.update({'font.size': 16})\n",
        "    ax  = fig.add_subplot(111)\n",
        "    matrix = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    fig.colorbar(matrix) \n",
        "    for i in range(0,6):\n",
        "        for j in range(0,6):  \n",
        "            ax.text(j,i,cm[i,j],va='center', ha='center')\n",
        "    ticks = np.arange(len(labels))\n",
        "    ax.set_xticks(ticks)\n",
        "    ax.set_xticklabels(labels, rotation=45)\n",
        "    ax.set_yticks(ticks)\n",
        "    ax.set_yticklabels(labels)\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "plot_confusion_matrix(y_true, y_pred, cmap=plt.cm.YlGnBu)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "DGhV0QJQyJEU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}